import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

print("=" * 60)
print("–ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–• –¢–ò–¢–ê–ù–ò–ö–ê")
print("=" * 60)

# --------------------------- –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ----------------------------
plt.figure(figsize=(15, 10))

# 1. –í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É –∏ –ø–æ–ª—É
plt.subplot(2, 3, 1)
sns.barplot(x='Pclass', y='Survived', hue='Sex', data=train_df)
plt.title('–í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –∫–ª–∞—Å—Å—É –∏ –ø–æ–ª—É')

# 2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞ –≤—ã–∂–∏–≤—à–∏—Ö/–ø–æ–≥–∏–±—à–∏—Ö
plt.subplot(2, 3, 2)
sns.histplot(data=train_df, x='Age', hue='Survived', bins=30, alpha=0.6)
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–æ–∑—Ä–∞—Å—Ç–∞')

# 3. –í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –ø–æ—Ä—Ç—É –ø–æ—Å–∞–¥–∫–∏
plt.subplot(2, 3, 3)
sns.barplot(x='Embarked', y='Survived', data=train_df)
plt.title('–í—ã–∂–∏–≤–∞–µ–º–æ—Å—Ç—å –ø–æ –ø–æ—Ä—Ç—É –ø–æ—Å–∞–¥–∫–∏')

# 4. –ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞
plt.subplot(2, 3, 4)
numeric_cols = ['Age', 'Fare', 'SibSp', 'Parch', 'Survived']
sns.heatmap(train_df[numeric_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞')

# 5. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞
plt.subplot(2, 3, 5)
sns.histplot(data=train_df, x='Fare', hue='Survived', bins=30, alpha=0.6)
plt.title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ç–æ–∏–º–æ—Å—Ç–∏ –±–∏–ª–µ—Ç–∞')

plt.tight_layout()
plt.savefig('titanic_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# --------------------------- –ü–û–î–ì–û–¢–û–í–ö–ê –§–ò–ß -----------------------------
# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–∏—Ç—É–ª–∞ –∏–∑ –∏–º–µ–Ω–∏ 
def extract_title(name):
    try:
        return name.split(', ')[1].split('.')[0]
    except:
        return 'Unknown'

train_df['Title'] = train_df['Name'].apply(extract_title)
test_df['Title'] = test_df['Name'].apply(extract_title)

# –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —Ç–∏—Ç—É–ª—ã
rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']
train_df['Title'] = train_df['Title'].replace('Mlle', 'Miss')
train_df['Title'] = train_df['Title'].replace('Ms', 'Miss')
train_df['Title'] = train_df['Title'].replace('Mme', 'Mrs')
train_df['Title'] = train_df['Title'].replace(rare_titles, 'Rare')

test_df['Title'] = test_df['Title'].replace('Mlle', 'Miss')
test_df['Title'] = test_df['Title'].replace('Ms', 'Miss')
test_df['Title'] = test_df['Title'].replace('Mme', 'Mrs')
test_df['Title'] = test_df['Title'].replace(rare_titles, 'Rare')

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è title
title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}
train_df['Title'] = train_df['Title'].map(title_mapping).fillna(0)
test_df['Title'] = test_df['Title'].map(title_mapping).fillna(0)

# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())
train_df['Embarked'] = train_df['Embarked'].fillna('C')

test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())
test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())
test_df['Embarked'] = test_df['Embarked'].fillna('C')

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è sex –∏ embarked
train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
train_df['Embarked'] = train_df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})

test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})
test_df['Embarked'] = test_df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})

# –°–æ–∑–¥–∞–µ–º —Ñ–∏—á–∏
train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1
train_df['IsAlone'] = (train_df['FamilySize'] == 1).astype(int)
train_df['IsLargeFamily'] = (train_df['FamilySize'] > 4).astype(int)

test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1
test_df['IsAlone'] = (test_df['FamilySize'] == 1).astype(int)
test_df['IsLargeFamily'] = (test_df['FamilySize'] > 4).astype(int)


# --------------------------- –§–ò–ù–ê–õ–¨–ù–´–ô –í–´–ë–û–† –§–ò–ß --------------------------------
feature_columns = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 
                   'Title', 'FamilySize', 'IsAlone', 'IsLargeFamily']

print(f"üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ñ–∏—á–∏ ({len(feature_columns)}): {feature_columns}")

X = train_df[feature_columns]
y = train_df['Survived']

X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# --------------------------- –°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô -----------------------------
models = {
    'Logistic Regression': LogisticRegression(C=1.0, random_state=42, max_iter=1000),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)
}

print("\n" + "="*50)
print("–°–†–ê–í–ù–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
print("="*50)

best_model = None
best_score = 0

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_val)
    accuracy = accuracy_score(y_val, y_pred)
    
    # –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
    cv_scores = cross_val_score(model, X, y, cv=5)

    print(f"\n{name}:")
    print(f"‚úÖ Accuracy: {accuracy:.4f}")
    print(f"üìä Cross-val: {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
    
    if accuracy > best_score:
        best_score = accuracy
        best_model = model
        best_model_name = name

# --------------------------- –§–ò–ù–ê–õ–¨–ù–ê–Ø –ú–û–î–ï–õ–¨ -----------------------------
print(f"\nüéØ –õ–£–ß–®–ê–Ø –ú–û–î–ï–õ–¨: {best_model_name} ({best_score:.4f})")

# –î–µ—Ç–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
y_pred = best_model.predict(X_val)
print("\nüìà –î–ï–¢–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê:")
print(classification_report(y_val, y_pred))

# –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
plt.figure(figsize=(8, 6))
cm = confusion_matrix(y_val, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['–ü–æ–≥–∏–±', '–í—ã–∂–∏–ª'], 
            yticklabels=['–ü–æ–≥–∏–±', '–í—ã–∂–∏–ª'])
plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Confusion Matrix)')
plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.show()

# Feature Importance –¥–ª—è Random Forest
if hasattr(best_model, 'feature_importances_'):
    plt.figure(figsize=(10, 6))
    feature_imp = pd.Series(best_model.feature_importances_, index=feature_columns)
    feature_imp.sort_values().plot(kind='barh')
    plt.title('–í–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (Random Forest)')
    plt.tight_layout()
    plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')
    plt.show()

# --------------------------- –°–ê–ë–ú–ò–¢ –ù–ê KAGGLE -----------------------------
X_test = test_df[feature_columns]
test_predictions = best_model.predict(X_test)

submission = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Survived': test_predictions
})

submission.to_csv('titanic_submission.csv', index=False)
print(f"\n‚úÖ –°–ê–ë–ú–ò–¢ –°–û–ó–î–ê–ù: titanic_submission.csv")
print(f"üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–æ –≤—ã–∂–∏–≤—à–∏—Ö: {test_predictions.sum()} –∏–∑ {len(test_predictions)}")
print(f"üéØ –ü—Ä–æ—Ü–µ–Ω—Ç –≤—ã–∂–∏–≤—à–∏—Ö: {test_predictions.sum()/len(test_predictions)*100:.1f}%")

# –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
print(f"\n{'='*50}")
print("–ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
print(f"{'='*50}")
print(f"–í—Å–µ–≥–æ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤ –≤ train: {len(train_df)}")
print(f"–í—ã–∂–∏–≤—à–∏—Ö –≤ train: {train_df['Survived'].sum()} ({train_df['Survived'].mean()*100:.1f}%)")
print(f"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model_name}")
print(f"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_score:.4f}")